{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SegFormer Quantization Pipeline","text":"<p>An end-to-end evaluation pipeline for SegFormer models on semantic segmentation tasks, with support for various quantization methods.</p> <p> </p>"},{"location":"#status","title":"Status","text":"<p>DRAFT ----&gt; Not fully implemented yet</p> <p>The current version is &lt;0.2.1&gt;. For version history have a look at the CHANGELOG.</p>"},{"location":"#toc","title":"TOC","text":"<ul> <li>Features</li> <li>Setup</li> <li>Usage</li> <li>Configuration</li> <li>Project Structure</li> <li>Documentation</li> <li>UML</li> <li>TODO</li> <li>License</li> </ul>"},{"location":"#features","title":"Features \u2191","text":"<ul> <li>Model loading and quantization (float8, int8, int4, int2)</li> <li>Dataset processing and sharding</li> <li>Evaluation metrics computation (mean IoU, mean accuracy, overall accuracy)</li> <li>Integration with Weights &amp; Biases for experiment tracking</li> </ul>"},{"location":"#setup","title":"Setup \u2191","text":"<ol> <li>Install dependencies: <code>pip install poetry==1.8.4 &amp;&amp; poetry install</code>.</li> <li>Set up Weights &amp; Biases API key in environment variables</li> </ol>"},{"location":"#usage","title":"Usage \u2191","text":"<pre><code>python -m app/app.py\n</code></pre> <p>or</p> <pre><code>docker build -t segformer-quant-eval .\ndocker run segformer-quant-eval\n</code></pre>"},{"location":"#configuration","title":"Configuration \u2191","text":"<p>Adjust settings in <code>app/config.py</code> for model, dataset, and evaluation parameters.</p>"},{"location":"#documentation","title":"Documentation \u2191","text":"<p>Documentation SegFormer Quantization Pipeline</p>"},{"location":"#project-structure","title":"Project Structure \u2191","text":"<pre><code>/\n\u251c\u2500\u2500 app/\n\u2502 \u251c\u2500\u2500 app.py\n\u2502 \u251c\u2500\u2500 config.py\n\u2502 \u2514\u2500\u2500 utils/\n\u2502   \u251c\u2500\u2500 data_processing.py\n\u2502   \u251c\u2500\u2500 evaluator.py\n\u2502   \u251c\u2500\u2500 general_utils.py\n\u2502   \u251c\u2500\u2500 model_loader.py\n\u2502   \u251c\u2500\u2500 quantization.py\n\u2502   \u2514\u2500\u2500 wandb_utils.py\n\u2514\u2500\u2500 pyproject.toml\n</code></pre>"},{"location":"#uml","title":"UML \u2191","text":""},{"location":"#todo","title":"TODO \u2191","text":"<ul> <li>[ ] Implement tests before concrete function (TDD)<ul> <li>test_model_loading, test_image_preprocessing</li> <li>test_quantization, test_predict, test_end_to_end</li> </ul> </li> <li>[ ] Include option to call HF API instead of saving model locally</li> <li>[ ] Use pydantic and python typing</li> <li>[ ] Insert link to and report of WandB project</li> <li>mkdocs<ul> <li>[x] Add .md to LICENSE/LICENSES to avoid download instead of open</li> <li>[x] Remove/Change #href \u2191(#toc) to avoid conflict with gh-pages</li> <li>[x] Remove/Change #href for light/dark png to avoid conflict with gh-pages</li> </ul> </li> </ul>"},{"location":"#license","title":"License \u2191","text":"<p>This project is licensed under the BSD 3-Clause License. See the LICENSE file for details. For third-party licenses, see the LICENSES file.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning, i.e. MAJOR.MINOR.PATCH (Breaking.Feature.Patch).</p> <p>Types of changes:</p> <ul> <li><code>Added</code> for new features.</li> <li><code>Changed</code> for changes in existing functionality.</li> <li><code>Deprecated</code> for soon-to-be removed features.</li> <li><code>Removed</code> for now removed features.</li> <li><code>Fixed</code> for any bug fixes.</li> <li><code>Security</code> in case of vulnerabilities.</li> </ul>"},{"location":"CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"CHANGELOG/#021-2024-11-17","title":"[0.2.1] - 2024-11-17","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Dockerfile</li> <li>Bumpversion for push and PR on <code>main</code></li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Extension .md for LICENSE(S) for mkdocs output</li> </ul>"},{"location":"CHANGELOG/#020-2024-11-17","title":"[0.2.0] - 2024-11-17","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>Management: <code>pyproject.toml</code></li> <li>Documentation: <code>PRD.md</code>, <code>FRD.md</code>, <code>DRD.md</code></li> <li>Documentation gh-pages: <code>generate-deploy-mkdocs-ghpages.yml</code> </li> <li>Versioning: <code>CHANGELOG.md</code>, GHA Bump2version</li> <li>Standarization: <code>.gitmessage</code></li> <li>Third-party <code>LICENSES</code></li> <li>mkdocs: <code>__init__.py</code></li> <li>Packaging: <code>__main__.py</code></li> </ul>"},{"location":"CHANGELOG/#changed_1","title":"Changed","text":"<ul> <li><code>LICENSE</code></li> <li><code>.gitignore</code></li> <li>Actions: <code>links-fail-fast.yml</code>, <code>codeql.yml</code></li> </ul>"},{"location":"CHANGELOG/#removed","title":"Removed","text":"<ul> <li><code>.bumpversion.cfg</code></li> <li><code>requirements.txt</code></li> </ul>"},{"location":"DRD/","title":"Design Requirements Document (DRD)","text":""},{"location":"DRD/#system-architecture","title":"System Architecture","text":"<p>The evaluation pipeline is designed with a modular architecture to ensure flexibility and extensibility. The main components are:</p> <ol> <li>Configuration Module</li> <li>Model Management Module</li> <li>Data Processing Module</li> <li>Evaluation Module</li> <li>Experiment Tracking Module</li> <li>Utility Module</li> </ol>"},{"location":"DRD/#module-specifications","title":"Module Specifications","text":""},{"location":"DRD/#1-configuration-module-appconfigpy","title":"1. Configuration Module (app/config.py)","text":"<ul> <li>Define global variables and constants</li> <li>Manage environment variables</li> <li>Set up paths for model and dataset storage</li> </ul>"},{"location":"DRD/#2-model-management-module-apputilsmodel_loaderpy-modelsquantizationpy","title":"2. Model Management Module (app/utils/model_loader.py, models/quantization.py)","text":"<ul> <li>Implement functions to load pre-trained SegFormer models</li> <li>Apply quantization techniques (float8, int8, int4, int2)</li> <li>Manage model storage and retrieval</li> </ul>"},{"location":"DRD/#3-data-processing-module-apputilsdata_processingpy","title":"3. Data Processing Module (app/utils/data_processing.py)","text":"<ul> <li>Implement dataset loading and preprocessing functions</li> <li>Handle data sharding for efficient processing</li> <li>Convert images and annotations to appropriate formats</li> </ul>"},{"location":"DRD/#4-evaluation-module-apputilsevaluatorpy","title":"4. Evaluation Module (app/utils/evaluator.py)","text":"<ul> <li>Implement the main evaluation loop</li> <li>Calculate and aggregate evaluation metrics</li> <li>Handle batch processing of data</li> </ul>"},{"location":"DRD/#5-experiment-tracking-module-apputilswandb_utilspy","title":"5. Experiment Tracking Module (app/utils/wandb_utils.py)","text":"<ul> <li>Initialize and manage Weights &amp; Biases runs</li> <li>Log metrics, model metadata, and performance data</li> <li>Create visualizations for result analysis</li> </ul>"},{"location":"DRD/#6-utility-module-apputilsgeneral_utilspy","title":"6. Utility Module (app/utils/general_utils.py)","text":"<ul> <li>Implement helper functions for data conversion</li> <li>Provide utility functions for file management and error handling</li> </ul>"},{"location":"DRD/#data-flow","title":"Data Flow","text":"<ol> <li>Configuration is loaded and environment is set up</li> <li>Pre-trained model is loaded and quantized</li> <li>Dataset is loaded, preprocessed, and sharded</li> <li>Evaluation loop processes data in batches:    a. Data is fed through the model    b. Predictions are generated    c. Metrics are calculated</li> <li>Results are logged to Weights &amp; Biases</li> <li>Process repeats for each quantization method</li> </ol>"},{"location":"DRD/#interface-design","title":"Interface Design","text":"<p>The system will primarily be used through a command-line interface. The main entry point will be <code>main.py</code>, which will coordinate the execution of all modules.</p>"},{"location":"DRD/#error-handling-and-logging","title":"Error Handling and Logging","text":"<ul> <li>Implement comprehensive error handling throughout the pipeline</li> <li>Use Python's logging module for consistent log output</li> <li>Integrate error reporting with Weights &amp; Biases for centralized monitoring</li> </ul>"},{"location":"DRD/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use environment variables for sensitive information (e.g., API keys)</li> <li>Implement proper error handling to avoid exposing system information in stack traces</li> </ul>"},{"location":"DRD/#scalability-and-performance","title":"Scalability and Performance","text":"<ul> <li>Design the system to efficiently utilize available GPU resources</li> <li>Implement data sharding to handle large datasets</li> <li>Use batch processing to optimize memory usage and computation time</li> </ul>"},{"location":"DRD/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Implement unit tests for individual modules</li> <li>Create integration tests for the entire pipeline</li> <li>Use a small subset of the dataset for quick testing and debugging</li> </ul>"},{"location":"DRD/#deployment-considerations","title":"Deployment Considerations","text":"<ul> <li>Provide clear documentation for setting up the environment and dependencies</li> <li>Consider containerization (e.g., Docker) for consistent deployment across different systems</li> </ul>"},{"location":"FRD/","title":"Functional Requirements Document (FRD)","text":""},{"location":"FRD/#system-components","title":"System Components","text":"<ol> <li>Model Management</li> <li>Load pre-trained SegFormer models</li> <li>Apply quantization techniques (float8, int8, int4, int2)</li> <li> <p>Save and load quantized models</p> </li> <li> <p>Data Processing</p> </li> <li>Load and preprocess the Scene Parse 150 dataset</li> <li>Implement efficient data sharding for large datasets</li> <li> <p>Convert images and annotations to appropriate formats</p> </li> <li> <p>Evaluation Pipeline</p> </li> <li>Implement inference function for SegFormer models</li> <li>Calculate evaluation metrics (mean IoU, mean accuracy, overall accuracy)</li> <li> <p>Process evaluation in batches for efficiency</p> </li> <li> <p>Experiment Tracking</p> </li> <li>Initialize and manage Weights &amp; Biases runs</li> <li>Log model performance metrics and metadata</li> <li> <p>Create visualizations for easy comparison of quantization methods</p> </li> <li> <p>Utility Functions</p> </li> <li>Manage environment variables and configuration</li> <li>Implement helper functions for data conversion and processing</li> </ol>"},{"location":"FRD/#functional-requirements","title":"Functional Requirements","text":"<ol> <li>The system shall load pre-trained SegFormer models from local storage or Hugging Face.</li> <li>The system shall apply specified quantization techniques to the loaded models.</li> <li>The system shall efficiently load and preprocess the Scene Parse 150 dataset.</li> <li>The system shall implement a data sharding mechanism to handle large datasets.</li> <li>The system shall perform inference using the quantized models on the preprocessed data.</li> <li>The system shall calculate and log evaluation metrics for each quantized model.</li> <li>The system shall integrate with Weights &amp; Biases for experiment tracking and visualization.</li> <li>The system shall provide a modular structure allowing easy extension to additional models and datasets.</li> </ol>"},{"location":"FRD/#performance-requirements","title":"Performance Requirements","text":"<ol> <li>The evaluation pipeline shall process the entire Scene Parse 150 validation set in under 24 hours on a single GPU.</li> <li>The system shall use GPU acceleration when available to speed up model inference.</li> <li>The memory usage shall not exceed 12GB of GPU memory at any point during execution.</li> </ol>"},{"location":"FRD/#usability-requirements","title":"Usability Requirements","text":"<ol> <li>The system shall provide clear console output indicating progress and any errors.</li> <li>Configuration of experiments shall be possible through a single configuration file.</li> <li>The system shall generate comprehensive logs and visualizations in Weights &amp; Biases for easy analysis.</li> </ol>"},{"location":"LICENSE/","title":"License","text":"<p>BSD 3-Clause License</p> <p>Copyright (c) 2024 qte77</p> <p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p> <ol> <li> <p>Redistributions of source code must retain the above copyright notice, this    list of conditions and the following disclaimer.</p> </li> <li> <p>Redistributions in binary form must reproduce the above copyright notice,    this list of conditions and the following disclaimer in the documentation    and/or other materials provided with the distribution.</p> </li> <li> <p>Neither the name of the copyright holder nor the names of its    contributors may be used to endorse or promote products derived from    this software without specific prior written permission.</p> </li> </ol> <p>THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>"},{"location":"LICENSES/","title":"Third-Party Licenses","text":"<p>Third-Party Licenses</p> <p>This project uses the following third-party libraries:</p> <ol> <li> <p>PyTorch    License: BSD-3-Clause    https://github.com/pytorch/pytorch/blob/master/LICENSE</p> </li> <li> <p>Transformers    License: Apache-2.0    https://github.com/huggingface/transformers/blob/main/LICENSE</p> </li> <li> <p>Evaluate    License: Apache-2.0    https://github.com/huggingface/evaluate/blob/main/LICENSE</p> </li> <li> <p>Quanto    License: Apache-2.0    https://github.com/huggingface/quanto/blob/main/LICENSE</p> </li> <li> <p>Weights &amp; Biases (wandb)    License: MIT    https://github.com/wandb/wandb/blob/main/LICENSE</p> </li> </ol> <p>Please refer to the respective project websites or source code repositories for the full license texts.</p>"},{"location":"PRD/","title":"Product Requirements Document (PRD)","text":""},{"location":"PRD/#product-vision","title":"Product Vision","text":"<p>Create a robust and efficient quantization evaluation pipeline for SegFormer models, enabling to assess and compare the performance of various quantization methods in semantic segmentation tasks.</p>"},{"location":"PRD/#target-users","title":"Target Users","text":"<ul> <li>Machine Learning Researchers</li> <li>Computer Vision Engineers</li> <li>MLOps Professionals</li> </ul>"},{"location":"PRD/#key-features","title":"Key Features","text":"<ol> <li>Model Loading and Quantization</li> <li>Support for loading pre-trained SegFormer models</li> <li> <p>Implementation of multiple quantization methods (float8, int8, int4, int2)</p> </li> <li> <p>Dataset Processing</p> </li> <li>Efficient handling of large datasets through sharding</li> <li> <p>Support for Scene Parse 150 dataset</p> </li> <li> <p>Evaluation Pipeline</p> </li> <li>Comprehensive evaluation metrics (mean IoU, mean accuracy, overall accuracy)</li> <li> <p>Batch processing for efficient evaluation</p> </li> <li> <p>Experiment Tracking</p> </li> <li>Integration with Weights &amp; Biases for logging and visualizing results</li> <li> <p>Automatic logging of model size and performance metrics</p> </li> <li> <p>Modular Design</p> </li> <li>Easy extension to support additional models and datasets</li> <li>Flexible configuration options</li> </ol>"},{"location":"PRD/#success-criteria","title":"Success Criteria","text":"<ul> <li>Successfully evaluate SegFormer models with different quantization levels</li> <li>Achieve a balance between model size reduction and performance maintenance</li> <li>Provide clear, actionable insights through experiment tracking and visualization</li> </ul>"},{"location":"PRD/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Support for additional semantic segmentation datasets</li> <li>Integration of more quantization methods</li> <li>Automated hyperparameter tuning for optimal quantization</li> </ul>"},{"location":"docstrings/","title":"Code Documentation","text":"<p>SegFormer evaluation pipeline for semantic segmentation tasks.</p> <p>This module orchestrates the evaluation of SegFormer models with various quantization methods on the Scene Parse 150 dataset. It handles model loading, quantization, dataset preparation, evaluation, and result logging using Weights &amp; Biases.</p> <p>The pipeline supports multiple quantization levels and efficient processing through dataset sharding. Results are tracked and visualized for performance analysis across different model configurations.</p> Usage <p>python app.py</p> Environment variables <p>WANDB_API_KEY: API key for Weights &amp; Biases logging WANDB_PROJECT: Name of the W&amp;B project WANDB_ENTITY: Name of the W&amp;B entity (team or user)</p>"},{"location":"docstrings/#app.main","title":"<code>main()</code>","text":"<p>Main execution function for the SegFormer evaluation pipeline.</p> <p>This function orchestrates the entire evaluation process, including model loading, dataset preparation, evaluation, and logging results.</p> Source code in <code>app/app.py</code> <pre><code>def main():\n    \"\"\"\n    Main execution function for the SegFormer evaluation pipeline.\n\n    This function orchestrates the entire evaluation process, including\n    model loading, dataset preparation, evaluation, and logging results.\n    \"\"\"\t\n\n    base_model = load_base_model(model_name, model_save_path, compute_dtype, device)\n    image_processor = load_image_processor(model_name, tokenizer_save_path)\n    dataset = load_dataset_custom(dataset_save_path, dataset_name)\n    wandb.login(relogin=True, force=True, key=environ['WANDB_API_KEY'])\n\n    # Quantize models\n    models = quantize_models(base_model, model_name, model_save_path, device)\n    print_model_sizes(models)\n\n    # Evaluation loop\n    ds_subset = 'validation'\n    for model_name, model in models.items():\n        model.eval()\n        for k in range(0, ds_num_shards):\n            if k == 0 or k % ds_shards_mod == 0:\n                print(f\"Evaluating {model_name}, shard {k}/{ds_num_shards}\")\n            wandb_run = create_wandb_run(\n                environ['WANDB_PROJECT'], environ['WANDB_ENTITY'],\n                model_name, dataset_name\n            )\n            create_wandb_run_meta(\n                wandb_run, model_name, dataset_name, device, wandb_tag_mode,\n                model_name, model, ds_num_shards, ds_shards_mod\n            )\n            dataset_shard = dataset[ds_subset].shard(\n                num_shards=ds_num_shards, index=k\n            )\n            results = evaluate_model(\n                model, dataset_shard, image_processor, device,\n                metric_name, model.config.id2label\n            )\n            log_wandb_results(results, model)\n            wandb.finish()\n</code></pre>"}]}